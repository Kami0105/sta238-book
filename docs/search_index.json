[
["index.html", "STA238: Probability, Statistics, and Data Analysis Chapter 1 Introduction", " STA238: Probability, Statistics, and Data Analysis Alison Gibbs and Alex Stringer 2019-09-16 Chapter 1 Introduction This book contains course materials for STA238: Probability, Statistics, and Data Analysis, at the University of Toronto, Department of Statistical Sciences. "],
["statistics-and-plots.html", "Chapter 2 Statistics and Plots 2.1 Introduction 2.2 Descriptive Statistics 2.3 Extended example: the state of rental housing in Toronto", " Chapter 2 Statistics and Plots 2.1 Introduction Data only becomes information after it is analyzed. Analyzing data is extraordinarily difficult, but is the only way to learn meaningfully about the world. In this book, you will learn about analyzing data. You will learn how to make principled, measured statements about the data on hand (descriptive statistics); how to use the data on hand to make statements about the underlying world, and how to quantify the uncertainty in your statements (inferential statistics), and how to use the data on hand to make judgements, with uncertainty quantification, about what data you will see next (predective statistics). This chapter focussed on descriptive statistics. This loosely refers to the set of principles and tools that you use to tell a story using available data. The data may be collected from a formal scientific experiment, or might be from a survey which relies on a random sample of a population. It could exist already in a big database at a bank or insurance company, or it could be scraped from the web. In all cases, the sitation is: you have data, and you want to use it to tell a story. 2.2 Descriptive Statistics Like with usual storytelling, how you present the data makes a big difference. There is no one correct way to analyze any given dataset. You will make judgements, and assumptions, and you will have to justify and explain them. These judgements and assumptions can have a profound impact on the story you tell using your data. For example, consider a famous dataset containing information on smoking and mortality. The data is available in the R package faraway. We may load the package and data and retrieve information on it as follows: # install.packages(&quot;faraway&quot;) # Run this to install the faraway package library(faraway) # Attach the faraway package data(&quot;femsmoke&quot;) # Load the &quot;femsmoke&quot; data # ?femsmoke # Run this to open the help page for the dataset. Lines in R that begin with a pound sign (or “hashtag” for the younger, more hip reader), \\(\\#\\), are comments and are not run. Remove the \\(\\#\\) to run the code. We see from the help page, and associated reference to the paper in the American Statistician, that the data comes from asking women in Newcastle, England, whether they smoke or not, and then following up in 20 years to see if they died. We can use these data to observe any apparent association between smoking and mortality. To investigate any such associations, we can simply look at the observed mortality rates for smokers and non-smokers. This is our first statistic. What makes it a “statistic”? Formally, a statistic is any summary—or function—of observed data. Here we are going to report the mortality rate—the proportion of people who died—for smokers, and non-smokers. These are both statistics, and reporting these two statistics side by side is our first example of an exploratory data analysis. # install.packages(&quot;tidyverse&quot;) library(tidyverse) # We use a LOT of functions from this package. # Compute the mortality rate for smokers and non-smokers. # To do this, create a dataframe containing the numbers of smokers # and non-smokers smoker_numbers &lt;- femsmoke %&gt;% # The %&gt;% operator lets you form sequences of operations group_by(smoker) %&gt;% # group_by() makes all the following operations happen within groups summarize(num_people = sum(y)) # Count the number of people who are smokers and not smokers smoker_numbers ## # A tibble: 2 x 2 ## smoker num_people ## &lt;fct&gt; &lt;dbl&gt; ## 1 yes 582 ## 2 no 732 # Now, compute the number of people who died out of the smokers and non-smokers # This looks the same as above, except we now filter() only the people who died. smoker_numbers_dead &lt;- femsmoke %&gt;% filter(dead == &quot;yes&quot;) %&gt;% # Retains rows where dead == &quot;yes&quot; only group_by(smoker) %&gt;% summarize(num_dead = sum(y)) smoker_numbers_dead ## # A tibble: 2 x 2 ## smoker num_dead ## &lt;fct&gt; &lt;dbl&gt; ## 1 yes 139 ## 2 no 230 # Now, we join these two tables together and compute the mortality rates by group. smoker_numbers %&gt;% inner_join(smoker_numbers_dead,by = &quot;smoker&quot;) %&gt;% # Joins rows with the same value of &quot;smoker&quot; mutate(mort_rate = num_dead/num_people) # mutate() creates a new variable, which can be a function of the other variables in the dataframe. ## # A tibble: 2 x 4 ## smoker num_people num_dead mort_rate ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 yes 582 139 0.239 ## 2 no 732 230 0.314 See anything interesting? What went wrong? Why are we observing that smokers have a lower mortality rate than non-smokers? Two possibilites immediately come to mind: The opposite is really true, however, we got a very unlikely dataset; We made a mistake in our analysis. We will address the first notion when we discuss inferential statistics later in the course. The second notion is more immediate. Did we make a mistake? One thing we definitely did was ignore some present information. Specifically, we also know how old the women were. How can we include this information in our descriptive statistics? We can compute mortality rates by age: smoker_numbers_age &lt;- femsmoke %&gt;% group_by(smoker,age) %&gt;% # Now we&#39;re grouping by smoker AND age. The rest of the code remains unchanged. summarize(num_people = sum(y)) smoker_numbers_age_dead &lt;- femsmoke %&gt;% filter(dead == &quot;yes&quot;) %&gt;% group_by(smoker,age) %&gt;% summarize(num_dead = sum(y)) smoker_numbers_age %&gt;% inner_join(smoker_numbers_age_dead,by = c(&quot;smoker&quot;,&quot;age&quot;)) %&gt;% mutate(mort_rate = num_dead/num_people) ## # A tibble: 14 x 5 ## # Groups: smoker [2] ## smoker age num_people num_dead mort_rate ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 yes 18-24 55 2 0.0364 ## 2 yes 25-34 124 3 0.0242 ## 3 yes 35-44 109 14 0.128 ## 4 yes 45-54 130 27 0.208 ## 5 yes 55-64 115 51 0.443 ## 6 yes 65-74 36 29 0.806 ## 7 yes 75+ 13 13 1 ## 8 no 18-24 62 1 0.0161 ## 9 no 25-34 157 5 0.0318 ## 10 no 35-44 121 7 0.0579 ## 11 no 45-54 78 12 0.154 ## 12 no 55-64 121 40 0.331 ## 13 no 65-74 129 101 0.783 ## 14 no 75+ 64 64 1 Older people are more likely to die within the 20 year followup period. However, examining the raw counts of people in each group, we also see that in these data, older people are less likely to smoke than younger people. So in these data, less smokers died, because less smokers were old, and more old people died. But was our first analysis wrong? No. Our first analysis was fine: we computed the mortality rate in each group. The problem was in the reporting, or the way we told the story. We didn’t provide enough information when we said “the mortality rate for smokers was lower than for non-smokers”. We should have mentioned that this is averaging over all age groups. Even when we include age in the analysis, we ought to mention the fact that there are a whole lot of variables we could have measured but didn’t, and we are implicitly averaging over these too. Before moving on, get some practice doing exploratory analysis with the following exercises: 2.2.1 Exercises How many non-smoking 18-24 year olds are there in the femsmoke data? Answer first by reading the answer off of the table of mortality rates by age that was just presented. Now compute the number yourself in the following two ways: Use group_by() to group the data by smoker and age; summarize() to compute the number of people in each smoker/age group, and then filter() to retain only smoker == &quot;yes&quot; and age == &quot;18-24&quot;. Use filter(smoker == &quot;yes&quot;,age = &quot;18-24&quot;) to filter by both these variables, then use summarize() to compute the total number of people. What is the relative risk of mortality—the ratio of the mortality rates—for smoking 18-24 year olds vs non-smoking 18-24 year olds? Compute the answer manually by reading the numbers off the above table again. Then compute it using R by doing the following: Create two datasets using filter(): one containing smokers and one containing non-smokers. filter() out only the 18-24 year olds. This gives you two datasets each with only one row. For example, smokers &lt;- femsmoke %&gt;% filter(smoker == &quot;yes&quot;,age = &quot;18-24&quot;). inner_join() the two datasets together, using age as the by variable: smokers %&gt;% inner_join(???,by = &quot;age&quot;) Advanced: modify the above steps to create the following table of relative mortality rates. You should start from a cleaned up version of the mortality rate by age table: rates_by_age &lt;- smoker_numbers_age %&gt;% inner_join(smoker_numbers_age_dead,by = c(&quot;smoker&quot;,&quot;age&quot;)) %&gt;% mutate(mort_rate = num_dead/num_people) %&gt;% ungroup() # The data was previously grouped, we don&#39;t want this anymore Use dplyr::select() to remove and rename columns, see ?dplyr::select. ## # A tibble: 7 x 4 ## age smoker_mort_rate nonsmoker_mort_rate relative_risk ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 18-24 0.0364 0.0161 2.25 ## 2 25-34 0.0242 0.0318 0.760 ## 3 35-44 0.128 0.0579 2.22 ## 4 45-54 0.208 0.154 1.35 ## 5 55-64 0.443 0.331 1.34 ## 6 65-74 0.806 0.783 1.03 ## 7 75+ 1 1 1 2.3 Extended example: the state of rental housing in Toronto We saw a basic example in the smoking data of how the choices that we make while analyzing a dataset can lead to different conclusions. The smoking data is quite small, and there aren’t that many choices to make. Let’s take a look at something more complicated, modern, and topical. The RentSafeTO: Apartment Building Standards program is designed to help renters in the city of Toronto make informed choices about where to live, and to enforce a minimum standard of quality upon rental units within the city. With rents skyrocketing and home ownership not a reasonable option for most, having an informed view of the rental market is imperative. It also helps keep leaders accountable, specifically if we focus on social and community housing buildings. Comprehensive and fairly clean data from the program, along with specific information, is available at https://open.toronto.ca/dataset/apartment-building-evaluation/. Data for the following were downloaded on 2019/09/16. To start your analysis, go now and download the data and open it in a spreadsheet and have a look. Familiarize yourselves with the variable descriptions and how the data were collected. This somewhat tedious task is a first step of any data analysis, in academia, industry, government, or wherever. 2.3.1 Load the data The data are stored in a .csv file, which stands for “comma-separated-values”. Storing data in a text file with a separator, usually a comma, is very common. These are referred to as “flat files” in an industrial context, to distinguish them from data stored in databases. We may read the data into R using the read_csv function in the readr package. The readr package is part of the tidyverse package that we used before, so if you installed that package, you have it loaded. # https://open.toronto.ca/dataset/apartment-building-evaluation/ # install.packages(&quot;readr&quot;) # Read the data in. This means call the readr::read_csv() function, point it # to where you saved the data on your computer, and then save the result to a # variable. I am naming this variable &#39;apartmentdata&#39;. # Type ?readr::read_csv if you want to read about this function. apartmentdata &lt;- readr::read_csv( file = &quot;./data/apartment-data/toronto-apartment-building-evaluations.csv&quot; ) ## Parsed with column specification: ## cols( ## .default = col_double(), ## EVALUATION_COMPLETED_ON = col_character(), ## PROPERTY_TYPE = col_character(), ## RESULTS_OF_SCORE = col_character(), ## SITE_ADDRESS = col_character(), ## WARD = col_character() ## ) ## See spec(...) for full column specifications. The message displayed is telling you that readr::read_csv() guessed at what kind of data were in each column, i.e. numbers, letters, dates, etc. You should make sure, as I have while writing, that these are what you expect. You can get a concise view of this dataset using the glimpse function in the dplyr package, which is automatically loaded when you load the tidyverse: glimpse(apartmentdata) ## Observations: 3,446 ## Variables: 32 ## $ `_id` &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 1… ## $ BALCONY_GUARDS &lt;dbl&gt; NA, NA, NA, NA, 5, NA, 5, 3, 4, 4, 3… ## $ CONFIRMED_STOREYS &lt;dbl&gt; 28, 4, 3, 3, 29, 3, 7, 18, 17, 32, 4… ## $ CONFIRMED_UNITS &lt;dbl&gt; 457, 15, 26, 10, 272, 12, 95, 287, 3… ## $ ELEVATORS &lt;dbl&gt; 4, NA, NA, NA, 5, NA, 5, 4, 5, 4, NA… ## $ ENTRANCE_DOORS_WINDOWS &lt;dbl&gt; 3, 3, 3, 4, 5, 4, 4, 4, 3, 4, 4, 3, … ## $ ENTRANCE_LOBBY &lt;dbl&gt; 4, 3, 3, 4, 5, 4, 4, 4, 4, 4, 4, 4, … ## $ EVALUATION_COMPLETED_ON &lt;chr&gt; &quot;04/03/2019&quot;, &quot;05/24/2018&quot;, &quot;07/11/2… ## $ EXTERIOR_CLADDING &lt;dbl&gt; 3, 4, 4, 4, 5, 4, 5, 4, 4, 3, 3, 4, … ## $ EXTERIOR_GROUNDS &lt;dbl&gt; 3, 4, 3, 3, 5, 4, 5, 4, 3, 4, 3, 4, … ## $ EXTERIOR_WALKWAYS &lt;dbl&gt; 3, 5, 4, 4, 5, 4, 5, 4, 3, 4, 4, 3, … ## $ GARBAGE_BIN_STORAGE_AREA &lt;dbl&gt; 3, 4, 3, 3, 4, 3, 3, 3, 4, 4, 4, 4, … ## $ GARBAGE_CHUTE_ROOMS &lt;dbl&gt; 3, NA, NA, NA, 5, NA, 5, 4, 3, 4, 5,… ## $ GRAFFITI &lt;dbl&gt; 5, 5, 5, 5, 5, 4, 5, 4, 3, 4, 5, 5, … ## $ INTERIOR_LIGHTING_LEVELS &lt;dbl&gt; 3, 4, 4, 4, 5, 4, 4, 3, 3, 4, 3, 4, … ## $ INTERIOR_WALL_CEILING_FLOOR &lt;dbl&gt; 4, 3, 4, 4, 5, 4, 4, 3, 4, 4, 4, 3, … ## $ INTERNAL_GUARDS_HANDRAILS &lt;dbl&gt; 3, 4, 3, 4, 5, 4, 5, 4, 4, 4, 5, 4, … ## $ NO_OF_AREAS_EVALUATED &lt;dbl&gt; 18, 14, 14, 13, 19, 16, 17, 18, 19, … ## $ OTHER_FACILITIES &lt;dbl&gt; 4, NA, NA, NA, 5, NA, NA, NA, NA, NA… ## $ PARKING_AREA &lt;dbl&gt; 2, NA, NA, NA, 4, 3, 5, 2, 4, 4, 2, … ## $ PROPERTY_TYPE &lt;chr&gt; &quot;PRIVATE&quot;, &quot;PRIVATE&quot;, &quot;PRIVATE&quot;, &quot;SO… ## $ RESULTS_OF_SCORE &lt;chr&gt; &quot;Evaluation needs to be conducted in… ## $ RSN &lt;dbl&gt; 4365723, 4364249, 4408585, 4288126, … ## $ SCORE &lt;dbl&gt; 71, 77, 71, 78, 98, 76, 93, 72, 74, … ## $ SECURITY &lt;dbl&gt; 4, 3, 3, 4, 5, 4, 5, 3, 4, 4, 4, 4, … ## $ SITE_ADDRESS &lt;chr&gt; &quot;2350 DUNDAS ST W&quot;, &quot;9 STAG HILL D… ## $ STAIRWELLS &lt;dbl&gt; 4, 4, 3, 4, 5, 4, 5, 4, 4, 4, 3, 4, … ## $ STORAGE_AREAS_LOCKERS &lt;dbl&gt; NA, NA, NA, NA, NA, 4, NA, NA, 3, 4,… ## $ WARD &lt;chr&gt; &quot;04&quot;, &quot;19&quot;, &quot;11&quot;, &quot;04&quot;, &quot;07&quot;, &quot;03&quot;, … ## $ WATER_PEN_EXT_BLDG_ELEMENTS &lt;dbl&gt; 4, 4, 4, 4, 5, 4, 5, 4, 5, 3, 3, 4, … ## $ YEAR_BUILT &lt;dbl&gt; 1976, 1953, 1948, 1920, 2017, 1967, … ## $ YEAR_REGISTERED &lt;dbl&gt; 2018, 2018, 2018, 2017, 2018, 2017, … That’s bigger than the smoking data! 3,446 rental apartment buildings, each with 32 factors measured. The buliding’s address and Ward number are in there, which are helpful for characterizing neighbourhoods. 2.3.2 Do different wards have different quality housing? A Ward is an administrative district within the city that has a single city counsellor. If I’m thinking about moving to, or within, Toronto, I want to know: Do different wards have different quality housing?. In order to address this question we need to decide on the following: Variable of interest. How do we quantify our research question? We need to pick a measure of quality. Picking different measures can lead to different conclusions. Filters. Do we look at all apartment buildings? Should we look only at those built after, or before, a certain date? Only those that meet a certain minimum, or maximum, standard of quality according to our definition? Are there any other kinds of decisions we might have to consider? Methods. What kind of statistical tools should we use to address our research question? We need to pick descriptive statistics to report, and decide whether we want to include other auxillary variables in the analysis. Conclusions. How do we report our results? Tables, charts, maps? Should we include subjective, editorial commentary, or let the data speak for themselves? This is already overwhelming! Let’s make an attempt at it. I propose: Our variable of interest should be SCORE, which you know (because you read the documentation…) is the “overall score of the buliding”. Higher is better. The actual formula is included in the documentation of the data. We will filter the data to only include buildings where PROPERTY_TYPE == 'PRIVATE', which will restrict our analysis to not include social housing. The quality of social housing is an important social justice issue (that you will investigate in the exercises) but it’s somewhat separate (?) from the question of where to look for rental housing. Our methods will include looking at a table of average scores for each ward. We will also look at whether older or newer buildings receive better scores. We will summarize our conclusions through a subjective assessment of the above table of average scores. With these decisions made, we may proceed with our analysis using the tidyverse as follows: # First, select only the columns you want # This isn&#39;t strictly necessary but trust me, it makes # debugging WAY easier. # I&#39;m also renaming the columns so the dataframe looks prettier. # Again, trust me. This stuff matters. apartmentclean &lt;- apartmentdata %&gt;% dplyr::select(ward = WARD, score = SCORE, property_type = PROPERTY_TYPE, year_built = YEAR_BUILT, address = SITE_ADDRESS ) glimpse(apartmentclean) # Much nicer! ## Observations: 3,446 ## Variables: 5 ## $ ward &lt;chr&gt; &quot;04&quot;, &quot;19&quot;, &quot;11&quot;, &quot;04&quot;, &quot;07&quot;, &quot;03&quot;, &quot;17&quot;, &quot;17&quot;, &quot;0… ## $ score &lt;dbl&gt; 71, 77, 71, 78, 98, 76, 93, 72, 74, 78, 73, 76, 57… ## $ property_type &lt;chr&gt; &quot;PRIVATE&quot;, &quot;PRIVATE&quot;, &quot;PRIVATE&quot;, &quot;SOCIAL HOUSING&quot;,… ## $ year_built &lt;dbl&gt; 1976, 1953, 1948, 1920, 2017, 1967, 2015, 1970, 19… ## $ address &lt;chr&gt; &quot;2350 DUNDAS ST W&quot;, &quot;9 STAG HILL DR&quot;, &quot;130 MACP… # Apply filter(s). apartmentfiltered &lt;- apartmentclean %&gt;% filter(property_type == &quot;PRIVATE&quot;) # When filtering, always compare the filtered and unfiltered data to ensure # the result is as expected: glimpse(apartmentclean) ## Observations: 3,446 ## Variables: 5 ## $ ward &lt;chr&gt; &quot;04&quot;, &quot;19&quot;, &quot;11&quot;, &quot;04&quot;, &quot;07&quot;, &quot;03&quot;, &quot;17&quot;, &quot;17&quot;, &quot;0… ## $ score &lt;dbl&gt; 71, 77, 71, 78, 98, 76, 93, 72, 74, 78, 73, 76, 57… ## $ property_type &lt;chr&gt; &quot;PRIVATE&quot;, &quot;PRIVATE&quot;, &quot;PRIVATE&quot;, &quot;SOCIAL HOUSING&quot;,… ## $ year_built &lt;dbl&gt; 1976, 1953, 1948, 1920, 2017, 1967, 2015, 1970, 19… ## $ address &lt;chr&gt; &quot;2350 DUNDAS ST W&quot;, &quot;9 STAG HILL DR&quot;, &quot;130 MACP… glimpse(apartmentfiltered) ## Observations: 2,879 ## Variables: 5 ## $ ward &lt;chr&gt; &quot;04&quot;, &quot;19&quot;, &quot;11&quot;, &quot;07&quot;, &quot;03&quot;, &quot;17&quot;, &quot;17&quot;, &quot;08&quot;, &quot;1… ## $ score &lt;dbl&gt; 71, 77, 71, 98, 76, 93, 72, 74, 78, 73, 76, 57, 70… ## $ property_type &lt;chr&gt; &quot;PRIVATE&quot;, &quot;PRIVATE&quot;, &quot;PRIVATE&quot;, &quot;PRIVATE&quot;, &quot;PRIVA… ## $ year_built &lt;dbl&gt; 1976, 1953, 1948, 2017, 1967, 2015, 1970, 1976, 19… ## $ address &lt;chr&gt; &quot;2350 DUNDAS ST W&quot;, &quot;9 STAG HILL DR&quot;, &quot;130 MACP… nrow(apartmentclean) - nrow(apartmentfiltered) # Dropped 567 rows. ## [1] 567 # Now create the table of averages: apartmentfiltered %&gt;% group_by(ward) %&gt;% summarize(avg_score = mean(score)) ## # A tibble: 26 x 2 ## ward avg_score ## &lt;chr&gt; &lt;dbl&gt; ## 1 01 71.5 ## 2 02 NA ## 3 03 70.5 ## 4 04 68.2 ## 5 05 71.7 ## 6 06 72.1 ## 7 07 69.8 ## 8 08 73.5 ## 9 09 NA ## 10 10 NA ## # … with 16 more rows Bah! What happened? Why are there these NA values? NA is the value R uses to mean “missing”. We have to hope that whether a rental apartment building’s score is missing is not related to what that score is, that is, we hope apartments with higher or lower scores aren’t missing more often. We will ignore missingness for now. To do this, use the na.rm = TRUE option in mean: apartmentsummary &lt;- apartmentfiltered %&gt;% group_by(ward) %&gt;% summarize(avg_score = mean(score,na.rm = TRUE)) apartmentsummary ## # A tibble: 26 x 2 ## ward avg_score ## &lt;chr&gt; &lt;dbl&gt; ## 1 01 71.5 ## 2 02 73.0 ## 3 03 70.5 ## 4 04 68.2 ## 5 05 71.7 ## 6 06 72.1 ## 7 07 69.8 ## 8 08 73.5 ## 9 09 67.5 ## 10 10 72.2 ## # … with 16 more rows This isn’t a super friendly way of comparing these 26 numbers. We need some kind od visualization, or plot, so we can take one look and get an idea of what is going on. 2.3.3 Data visualization for description In order to pick what kind of plot to make, we have to understand what types of variables we are attempting to compare. Broadly speaking, variables can either be continuous or categorical. A continuous variable consists of numbers. You can always compare the order of two values of a continuous variable (say whether one is bigger than the other), because its values are just numbers. A categorical variable takes values from a finite (discrete) set. These values can be anything. Categorical variables sometimes have values which can be compared, like “big”, “medium”, “small”; but often the values are not inherently comparable. In the case of the table of average scores by ward, we will consider avg_score to be a continuous variable and ward to be a categorical variable. Wards are labelled with numbers, yes, but they are not inherently comparable; they are areas within the city. It wouldn’t make sense to say that ward 2 were “less” than ward 17. We could have labelled them “A”, “B”, “C”,… and the meaning would have been the same. One common visualization used to compare values of a continuous variable with values of a categorical variable is a bar chart. A bar chart contains the values of the categorical variable on the x-axis and the values of the continuous variable on the y-axis. You can take one look and see whether there is any pattern in values of the continuous variable with respect to the categorical variable. We create a bar chart to visualize these summary statistics using the ggplot2 package. This is also included with the tidyverse (surprise!): apartmentsummary %&gt;% ggplot(aes(x = ward,y = avg_score)) + # Set up the variable mappings theme_light() + # Make it pretty geom_bar(stat = &quot;identity&quot;,colour = &quot;black&quot;,fill = &quot;grey&quot;) + # Add the bars labs(title = &quot;Average ABS score shows moderate variability across wards in Toronto&quot;, x = &quot;Ward&quot;, y = &quot;Average ABS Score&quot;) # Informative title It looks like some wards are better than others. Or are they? Can we make any definitive conclusions based on this? 2.3.4 Further analysis: trends in quality over time Let’s go further and analyze some other interesting aspects of these data. I’m interested in knowing: Are newer buildings higher quality? We have the score and the year_built, and we’d like to investigate whether newer buildings (higher year_built) have higher scores. We have another decision to make. We could consider year_built to be a categorical variable, and make a bar chart. Or, we could consider it to be a continuous variable. Because values of year_built are inherently comparable, and because our research question involves making such comparisons, we will consider year_built to be a continuous variable. One type of plot used to compare continuous variables is a scatterplot. A scatterplot has continuous variables on the x- and y-axes, and draws a point (or bubble) at each place in the two-dimensional plane where a datapoint occurs. We can make this kind of plot in ggplot2 as well. This time, we use the raw (well, cleaned and filtered) data: apartmentfiltered %&gt;% filter(year_built &gt; 1900) %&gt;% ggplot(aes(x = year_built,y = score)) + theme_light() + geom_point(pch = 21,colour = &quot;black&quot;,fill = &quot;grey&quot;) + # pch=21 makes the bubbles hollow, looks nice scale_x_continuous(breaks = seq(1900,2020,by=10)) + # Set the x-axis range labs(title = &quot;Less rental buildings are being built recently, but they are of higher quality&quot;, x = &quot;Year Built&quot;, y = &quot;ABS Score&quot;) ## Warning: Removed 5 rows containing missing values (geom_point). Very interesting. You can clearly see the baby boom of the 1950’s to 1970’s, followed by a massive slowdown in construction during the economic slump in the 1980’s, and a complete stop when rent control was introduced in 1991 (remember, these are rental buildings only). Then, we see a new wave of rental building construction, and the new buildings seem to be of higher quality. What are the highest and lowest quality rental buildings in Toronto? # Get the 10 highest scoring buildings apartmentfiltered %&gt;% arrange(desc(score)) %&gt;% # Sort the data, descending, by score slice(1:10) # Take the first ten- i.e. the top ten ## # A tibble: 10 x 5 ## ward score property_type year_built address ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 YY 99 PRIVATE 2018 561 SHERBOURNE ST ## 2 17 99 PRIVATE 2017 123 PARKWAY FOREST DR ## 3 16 99 PRIVATE 1963 70 PARKWOODS VILLAGE DR ## 4 07 98 PRIVATE 2017 2 VENA WAY ## 5 17 97 PRIVATE 1968 24 FOREST MANOR RD ## 6 12 96 PRIVATE 1960 42 GLEN ELM AVE ## 7 13 95 PRIVATE 2017 252 VICTORIA ST ## 8 02 95 PRIVATE 1969 500 SCARLETT RD ## 9 16 95 PRIVATE 1962 67 PARKWOODS VILLAGE DR ## 10 07 95 PRIVATE 2016 6 VENA WAY Wow. I know where I want to live. 2.3.5 Summary We have seen how even something simple like trying to figure out whether different areas of the city have different quality housing can require a lot of decision making. And these decisions require expertise. By taking a principled approach to learning data analysis, you are empowering yourself to live a life that is better informed. But notice that we didn’t really answer any questions in this chapter. We saw some rough patterns, but were they real? If we made different decisions, or if we sampled different data, would we have seen different patterns? In order to understand what the problem is and how to approach it, we need to take a more detailed look at the concept of error. This is the subject of Chapter 2. 2.3.6 Exercises Read the documentation online and choose three variables that you find the most interesting. Reproduce the analysis of sections 2.3.2. and 2.3.3. using your favourite variables. Is there more or less variability across wards than with score? What is the ward with the highest average score? In what ward is/are the building(s) with the highest score(s)? Is this the same ward, or not? Would you expect the ward with the highest average to also have the highest-scoring buildings? Repeat this question with the lowest scoring buildings instead of the highest. If you live in a rental apartment, find it in these data. If not, find a friend’s place. How does your building compare to other buildings in your ward? Does it score higher or lower? The filter() function is your friend here, or you can use apartmentfiltered %&gt;% arrange(SITE_ADDRESS) %&gt;% print(n = Inf) and then find yours in the list manually. Combine the analyses of sections 2.3.2 and 2.3.3. with that of 2.3.4. Specifically, make a table and a boxplot of the average score by year. This means replace ward by year_built in the analysis of sections 2.3.2. and 2.3.3. Do your conclusions change when comparing with 2.3.4? Why or why not? Would you expect this to always be the case? Advanced: analyze the quality of social housing in Toronto. Perform a similar analysis to what we performed here for PROPERTY_TYPE == 'PRIVATE', but instead for PROPERTY_TYPE %in% c('SOCIAL HOUSING','TCHC') (equivalent to PROPERTY_TYPE != 'PRIVATE'). Does the quality of social housing in Toronto vary greatly across different wards? Is it improving or degrading over time? Do you think we have enough information here to definitively answer these questions? "],
["error.html", "Chapter 3 Error", " Chapter 3 Error In this chapter we will more formally discuss the notion of error. "],
["mathematical-models.html", "Chapter 4 Mathematical Models", " Chapter 4 Mathematical Models In this chapter we will introduce a mathematical framework for quantifying uncertainty. "],
["computational-models.html", "Chapter 5 Computational Models", " Chapter 5 Computational Models In this section we will introduce a computational framework for quantifying uncertainty. "],
["incorporating-what-i-know-using-prior-information-to-inform-inferences.html", "Chapter 6 Incorporating what I know: using prior information to inform inferences", " Chapter 6 Incorporating what I know: using prior information to inform inferences In this chapter we will discuss formally incorporating information that is known beforehand into our inferences. "]
]
