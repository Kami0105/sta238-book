# Supplement to Chapters 17 and 19

This chapter implements much of the analysis shown in chapters 13 and 14 of 
A Modern Introduction to Probability and Statistics. R code is given for the
simple textbook datasets used in the book, and then the concepts are
illustrated on real data.

All datasets from the book can be downloaded here: https://www.tudelft.nl/en/eemcs/the-faculty/departments/applied-mathematics/applied-probability/education/mips/.

## Statistical models (Chapter 17)

Most of the material from chapter 17 is a review of that from chapters 15 and 16,
but in an important new context. You should be doing all exercises from chapter
17 **using R**, using the tools you have learned from chapters 15 and 16.

Here we will focus on the linear regression model. This chapter doesn't cover
how these models are estimated, so here we will show how to use `R` to plot
regression lines. We'll use `ggplot2` to recreate Figure 17.8, and show how 
to add "smooth" non-linear regression lines to plots as well.

The Janka Hardness dataset was already discussed in Chapter 15/16. Since you did
the exercises from those chapters prescribed in this supplementary book, you
have already read these data into `R`:

```{bash janka-0}
head data/MIPSdata/jankahardness.txt
````

By printing it out on the command line, you can tell that the file is *tab-delimited*.
Use `readr::read_delim()` to read it in:

```{r janka-1,warning=FALSE,message=FALSE}
library(tidyverse)
janka <- readr::read_delim(
  file = "data/MIPSdata/jankahardness.txt",
  delim = "\t",
  col_names = c("density","hardness"),
  col_types = "nn"
)
glimpse(janka)
```

Create a scatterplot with `ggplot2`:

```{r janka-2}
jankascatter <- janka %>%
  ggplot(aes(x = density,y = hardness)) +
  theme_classic() +
  geom_point() +
  scale_x_continuous(breaks = seq(20,80,by=10)) +
  scale_y_continuous(breaks = seq(0,3500,by=500)) +
  coord_cartesian(xlim = c(20,80),ylim = c(0,3500)) +
  labs(x = "Wood density",
       y = "Hardness")
jankascatter
```

To add a line to a plot, use `geom_abline()`. We can use this to recreate the regression
line from Figure 17.8:

```{r janka-3}
jankascatter + 
  geom_abline(slope = 57.51,intercept = -1160.5)
```

But how did the book calculate these values? We'll answer this question in a later
chapter. But for now, it would still be nice to get the computer to compute these
values for us rather than typing them in manually. We can do this using the 
`geom_smooth()` function in `ggplot2`:

```{r janka-4}
jankascatter +
  geom_smooth(method = "lm",se = FALSE,colour = "black",size = .5)
```

The "lm" stands for "linear model" and the "se" stands for "standard error"; leaving
this at its default of "TRUE" would add error bars to the line, which we'll learn
about later (give it a try though).

We can also add a non-linear curve to the plot using this technique. Most of the
approaches to doing non-linear regression involve breaking the data up into small
chunks based on the x-axis values, and then doing linear regression in each chunk
and joining the resulting lines. The "loess" non-linear regression line is an 
example of this approach. It roughly stands for "local regression and smoothing
splines". We can add this using `ggplot2` as well:

```{r janka-5}
jankascatter +
  geom_smooth(method = "loess",se = FALSE,colour = "black",size = .5)
```

See how it's a bit more wiggly, but still pretty straight? The data really does
look like it supports a linear relationship between density and hardness. This
is not common in modern practice!

### Extended example: TTC ridership revenues

Toronto's population is growing over time. This puts strain on our outdated
public transit system. But it should also lead to increased revenues. According to
(https://globalnews.ca/news/1670796/how-does-the-ttcs-funding-compare-to-other-transit-agencies/)[a news
article from a few years back], the TTC is the least-subsidized major transit agency
in North America, which means that its operating budget is the most dependent on
fare revenue out of any in all of the US and Canada. Tracking how ridership
revenues are changing over time is very important.

The city does do this. Go to (https://www.toronto.ca/city-government/data-research-maps/toronto-progress-portal/)[
the City of Toronto Progress Portal] and type "TTC" and click on the box that says
"TTC Ridership Revenues" to see a report. You can download the data from here, but
since it's a bit tricky to describe exactly how, I have posted the file
`ttc-ridership-revenues.csv` on Quercus. We are going to read these data into `R`
and analyze the relationship between `year` and `revenue`.

If you're thinking "that sounds really easy, we just did that!"... just keep reading.

First, print the data out and count the number of rows on the command line:

```{bash ttc-1}
head data/ttc-ridership-revenues.csv
wc -l data/ttc-ridership-revenues.csv
```

Yikes! Real data is messy. This data isn't even that messy and it still seems messy.

We see that the file is comma-separated and has a header. The first column is
text and the others are... well, they're supposed to be numeric, but they are
stored in the file with dollar signs. WHY! This kind of thing is super annoying 
and super common.

We could remove the dollar signs from the text file directly using `sed` or a
similar UNIX-based tool, but I prefer whenever possible to keep all my analysis
on one platform. We'll read it into `R` as-is and then parse and change datatypes
there:

```{r ttc-2}
# Read in the data
ridership <- readr::read_csv(
  file = "data/ttc-ridership-revenues.csv",
  col_names = TRUE, # Tells readr to read the column names from the first line of the file.
  col_types = stringr::str_c(rep("c",13),collapse = "") # Read all 13 columns as "c"haracter
)
glimpse(ridership)
```

This does not look like it's in a form ready to analyze. Some problems:

1. The `Year` has unwanted text in it. We just want the number representing what
year it is.
1. The revenue is stored across 12 columns, one for each month. We want the annual
revenue for our analysis.
1. The actual numeric revenue is stored as text with a dollar sign. We need to
parse out the number part and convert to a numeric datatype before we can analyze it.

Problems 1 and 3 require a bit of text parsing; Problem 2 requires converting from
"wide" to "long" format. Let's do it:

```{r ttc-3}
# PROBLEM 1: Year
# To parse out only the number part, use a regular expression.
# Our string starts with a four digit number which starts with 20. We want to capture this number
# and nothing else.
# The ^ means "the start of the string".
# The [20]{2} means "a 0 or a 2, exactly twice"
# The [0-9]{2} means "anything from 0 - 9, exactly twice"
year_regex <- "^[20]{2}[0-9]{2}"
# Use stringr::str_extract to extract a substring matching the regular expression:
stringr::str_extract("2007 YTD Actual",year_regex)

# PROBLEM 2: wide to long
# Use the tidyr::gather() function for "gather"ing columns and putting them
# into one column:
ridership %>%
  tidyr::gather(month,revenue,Jan:Dec)

# PROBLEM 3: removing the dollar sign
# Again, use text matching. Because $ is itself a special character,
# to match it, you have to "escape" it using a backslash
dollar_regex <- "\\$"
# Remove matching strings using stringr::str_remove()
stringr::str_remove("$1234",dollar_regex)

# Now, combine all these into one data cleaning pipeline.
# Remember we have monthly revenue, so to get yearly revenue, we sum
# over months.
ridership_clean <- ridership %>%
  tidyr::gather(month,revenue,Jan:Dec) %>% # "transmute" is like mutate, but it deletes all original columns
  transmute(year = stringr::str_extract(Year,year_regex),
            revenue = stringr::str_remove(revenue,dollar_regex)) %>%
  mutate_at(c("year","revenue"),as.numeric) %>% # Turn both year and revenue into numeric variables
  group_by(year) %>% # Sum revenue for each year to get yearly revenue
  summarize(revenue = sum(revenue)) %>%
  filter(year < 2019) # 2019 has incomplete data, so remove it
glimpse(ridership_clean)
```

That looks a lot better! As usual, you should run each line of code one by one to
understand what is happening.

Because we went to the effort of cleaning the data, we can now plot it easily:

```{r ttc-4}
ridershipscatter <- ridership_clean %>%
  ggplot(aes(x = year,y = revenue)) +
  theme_classic() +
  geom_point() +
  labs(title = "Annual ridership revenues for the TTC",
       x = "Year",
       y = "Revenue") +
  scale_y_continuous(labels = scales::dollar_format()) # Make the y-axis pretty
ridershipscatter
```

Add a linear and non-linear regression line:

```{r ttc-5}
leftplot <- ridershipscatter +
  geom_smooth(method = "lm",size = .5,se = FALSE,colour = "black") +
  labs(subtitle = "Linear regression line")
rightplot <- ridershipscatter +
  geom_smooth(method = "loess",size = .5,se = FALSE,colour = "black") +
  labs(subtitle = "Non-linear regression line",y = "")

cowplot::plot_grid(leftplot,
                   rightplot + theme(axis.text.y = element_blank()), # Take away the second plot's y-axis
                   nrow=1)
```

**Exercise**: re-do this analysis but don't sum over month. This will give 12 
points per year on the plot. Do one linear regression per month. 
Recreate the following plot yourself:

```{r ttc-6,include=FALSE}
ridership_month <- ridership %>%
  tidyr::gather(month,revenue,Jan:Dec) %>% # "transmute" is like mutate, but it deletes all original columns
  mutate(year = stringr::str_extract(Year,year_regex),
         revenue = stringr::str_remove(revenue,dollar_regex)) %>%
  mutate_at(c("year","revenue"),as.numeric) %>% # Turn both year and revenue into numeric variables
  filter(year < 2019) %>%
  dplyr::select(-Year)

ridership_month %>%
  ggplot(aes(x = year,y = revenue,group = month,colour = month)) +
  theme_classic() +
  geom_point() +
  geom_smooth(method = "lm",se = FALSE,size = .5) +
  labs(title = "Annual ridership revenues for the TTC",
       x = "Year",
       y = "Revenue") +
  scale_y_continuous(labels = scales::dollar_format())

```

To do this, you have to create a dataset that looks like this:

```{r ttc-7,include=FALSE}
glimpse(ridership_month)
```

You should make the following modifications:

1. Replace `transmute` with `mutate` so you don't delete the `month` column.
1. Replace `aes(x = year,y = revenue)` with `aes(x = year,y = revenue,group = month,colour = month)`
in the call to `ggplot`.
1. Don't sum over months.


